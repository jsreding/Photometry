# -*- coding: utf-8 -*-
"""
Created on Thu Jan 12 13:27:05 2017

@author: zvander
"""

#############################################################
##
##  The purpose of this script is to add important
##  info into the FITS headers of MULTI-FILTER data and 
##  subsequently separate the images by filter type.
##
##  This script MUST be run through the command line in the
##  folder where your images are contained.  It will prompt
##  you along the way and ask whether or not you want to
##  add/edit various header keywords and/or perform the 
##  image separation. Image separation works by simply  
##  moving the FITS file into a new filter-specific folder 
##  by looking at the FILTER keyword in the FITS header.  
##  This FITS keyword is added when running this script.
##
##  To run the entirety of this script, you will need a
##  list file, just like the ones IRAF uses, containing
##  the names of every FITS file to be operated on.  You
##  will also need a timestamps.csv file to add in the UT
##  start-of-exposure dates and times.  The timestamps file
##  is generated by Keaton Bell's OLDMAID software once it
##  has processed the entire SPE file for a given run.  For
##  filter information you will need the Filter_Wheel_Log.log 
##  file generated by Lightfield during data acquisition.
##  This file contains imformation on the filter wheel's
##  position for each image, as well as a plethora of other
##  information that can be added into the headers such as
##  telescope pointing and tracking, focus, and weather.
##  For now, this program ignores this extra info and just
##  adds in the filter and other basic info like exposure
##  time, object name, observer name, and instrument name.
##
##  Script created by Zach Vanderbosch
##  Last Update: 2018-02-25
##
#############################################################

import numpy  as np
import pandas as pd
import os
import sys
import glob
import errno
from math import isnan
from astropy.io import fits
from itertools import groupby
from operator import itemgetter
from datetime import datetime as dt
from datetime import timedelta as td

#############################################################
##
##  Progress Bar Code. I got this code from Stack Overflow, 
##  "Python to print out status bar and percentage"
##
#############################################################

## Provide the interation counter (count=int)
## and the action being performed (action=string)
def progress_bar(count,total,action):
    sys.stdout.write('\r')
    sys.stdout.write(action)
    sys.stdout.write("[%-20s] %d%%" % ('='*(count*20/total),\
                                            count*100/total))
    sys.stdout.flush()
    return


#########################################################
##
##  Currently, the filter sequence has to be hardcoded
##  in order perform cycle time calculations later on
##
#########################################################

filter_order = {'u':1.0,'g':2.0,'r':3.0,'i':4.0,'z':5.0,\
                'EMPTY':6.0,'BLOCK':7.0,'BG40':8.0}
trans_time = 1.49 ## Time required for one adjacent filter movement

#########################################################
##
##  Load in the file names and the log file
##
#########################################################

path = os.getcwd() + '/'  # Get the current working directory

## Ask the user to supply the name of a file
## containing a list of all images to be worked on
file_list = 'ilist'
log_file  = 'Filter_Wheel_Log.log' #Filename for metadata log file

## Loads in filenames as a list
try:
    filenames = np.loadtxt(path + file_list, dtype=str)
except:
    print('\nFile list by name "ilist" not found.')
    file_list = raw_input('Please enter a working list name or "q" to quit: ')
    if (file_list == 'q') or (file_list == 'Q'):  
        print('\nProgram TERMINATED\n')
        sys.exit(1)
    else:
        try:
            filenames = np.loadtxt(path + file_list, dtype=str)
        except:
            print('\nCould not load filelist by name %s' %file_list)
            print('Program TERMINATED\n')
            sys.exit(1)


# Loads in Image Meta Data from log file
try:
    meta_data = pd.read_csv(path+log_file, delim_whitespace=True, header=None, comment='#')
except IOError:
    print('')
    print('A Log File by the name Filter_Wheel_Log.log does not exist')
    print('If the file name is incorrect, please enter a new one.')
    new_log_file = raw_input('Log File Name (or press ENTER to exit): ')
    
    ## Try opening again with new provided log filename.
    ## This time, if unsuccessful, terminate the program
    try: 
        meta_data = pd.read_csv(path+new_log_file, delim_whitespace=True, header=None, comment='#')
    except IOError:
        print('')
        print('Log File by the name %s does not exist.' %new_log_file)
        print('Program TERMINATED.')
        print('')
        sys.exit(1)  
  
## Extract the filter and exposure time information from metadata      
expose_seq = meta_data[:][4]
filter_seq = meta_data[:][5]

## Save the original file names for comparison later
og_filenames = filenames
num_files    = len(filenames)


###############################################################
##
##  First, let's take a look at the MetaData log file and
##  try to reconstruct the filter wheel sequence.
##
###############################################################

## Take a look at the exposure times and filters in
## the log file and try to reconstruct the filter 
## wheel sequence.  This will be printed out for the
## user to check over before proceeding.  
texp_look = np.sort(np.unique(expose_seq))
farr,fidx = np.unique(filter_seq,return_index=True)
filt_look = filter_seq[np.sort(fidx)].reset_index(drop=True)
num_filt  = len(filt_look)
        
## Retrieve the logging information specific to each filter
infer_seq  = []  ## List to store the inferred filter sequence
print_seq  = []  ## List to store string for printing the filter sequence
seq_stats  = []  ## List to store some sequence stats
ttime_exp  = 0.0 ## Variable to store the total observation time
cycle_time = 0.0 ## Variable to store the total cycle time
down_time  = 0.0 ## Variable to store the total transition time

for filt_type in filt_look:
        
    ## First retreive the metadata for one filter type only
    idxfilt     = filter_seq[filter_seq == filt_type].index.tolist()
    filter_log  = meta_data.loc[idxfilt][:]
    filter_texp = filter_log[:][4]
    
    ## Calculate some metrics for the filter wheel sequence
    filt_ttime = np.sum(np.ceil(filter_texp)) ## Total time spent in given filter
    filt_tnumi = len(idxfilt)                 ## Total # of images in given filter    
    filt_stats = [filt_ttime,filt_tnumi]
    seq_stats.append(filt_stats)              ## Update the filter stats
    ttime_exp += filt_ttime                   ## Update total observation time
    
    ## Determine how many consecutive images are taken 
    ## per filter during one filter wheel cycle
    exp_counts = []
    for k,g in groupby(enumerate(filter_log[:][3]),lambda (i, x): i-x):
    
        frame_chunk = map(itemgetter(1), g)
        frame_span = frame_chunk[-1] - frame_chunk[0] + 1
        exp_counts.append(frame_span)
        
    ## Add information to the printed filter string and 
    ## store values into the inferred sequence list
    first_count   = exp_counts[0]
    first_texp    = round(filter_texp.loc[idxfilt[0]])
    filter_string = '%9s %4s %8.0i %11.1f'.rjust(9) %('',filt_type,first_count,first_texp)          
    print_seq.append(filter_string)

    
    ## Lastly, let's iteratively calculate the
    ## total cycle time, including transitions
    if filt_type != 'T':
        
        c      = filt_look[filt_look == filt_type].index[0]
        loc    = filter_order[filt_type]
        c_next = c+1
        
        ## Check to make sure we are skipping over
        ## the transition frame in the list and also
        ## that we are handling the indices right 
        ## when going from end to start of filt_look
        if c_next > num_filt-1:
            c_next = 0
            if filt_look[c_next] == 'T':
                c_next += 1
        elif filt_look[c_next] == 'T':
            c_next += 1
            if c_next > num_filt-1:
                c_next = 0
                     
        filt_type_next = filt_look[c_next]
        loc_next       = filter_order[filt_type_next]
        
        ## Calculate the difference between filter locations
        diff_loc = abs(loc_next - loc)
        if diff_loc > 4:
            diff_loc = 8 - diff_loc ## Accounts for FW's ability 
                                    ## to move both directions
            
        ## Calculate time to transition from the
        ## current filter to the next filter
        move_time = np.ceil(diff_loc * trans_time)
        
        ## Lastly, add move time to the total
        ## time spent in a given filter
        cycle_add_time = first_count * first_texp + move_time
        
        ## Add calculations onto the cumulative totals
        cycle_time += cycle_add_time
        down_time  += move_time

        ## add filter info into the inferred filter sequence list for later use
        infer_seq.append([filt_type,first_count,first_texp])
        infer_seq.append(['T',1,move_time])


## Print out the inferred filter wheel sequence and
## ask the user to confirm whether it is right or wrong
print('')
print('%9s  Inferred Filter Sequence  ' %'')
print('%9s----------------------------' %'')
print('%9sFilter   Num Exp.  T-exp (s)' %'')
for i in range(len(filt_look)):
    if filt_look[i] != 'T':
        print(print_seq[i])
    else:
        continue
print('\n\n             Filter Sequence Metrics             ')
print('-------------------------------------------------')
print('Filter   Total Exp.  Total Time(s)  Duty Cycle(%)')
for i in range(len(filt_look)):
    fil = filt_look[i]
    tnum = seq_stats[i][1]
    ttim = seq_stats[i][0]
    dcyc = seq_stats[i][0]/ttime_exp *1e2
    if i < len(filt_look) - 1:
        print('%4s %10i %13.1f %14.1f' %(fil,tnum,ttim,dcyc))
    else:
        print('%4s %10i %13.1f %14.1f \n\n' %(fil,tnum,ttim,dcyc))
print('%6s Total Observation Time (s): %7.1f' %('',ttime_exp))
print('%6s Filter Sequence Time (s)  : %7.1f' %('',cycle_time))
print('%6s Total Cycles Executed     : %7.1f' %('',ttime_exp/cycle_time))
print('%6s Sequence Duty Cycle (%s)   : %7.1f' %('','%',down_time/cycle_time*1e2))
print('\nPLEASE CHECK THE INFERRED SEQUENCE FOR ERRORS.')
    

###############################################################
##
##  A filter wheel disconnection issue can cause a number of 
##  inconsistencies to appear in the log file which we will
##  attempt to check for here.  The user will be alerted 
##  if any of the data quality tests are failed, but the 
##  program will continue to run.
##
##  Inform the user that we will now perform a quality check on 
##  the Filter_Wheel_Log file using the inferred sequence
##
###############################################################
print('\n#####################################################')
print('##   This section will check the Filter Wheel Log  ##')
print('##      for errors using the inferred sequence     ##')
print('#####################################################')
continue_running = raw_input('\nPerform quality check? (Y/[N]): ')

if (continue_running == 'Y') or (continue_running == 'y'): 

    ## Quick check on the number of filnames vs. Filter Wheel Log entries
    data_len1 = len(filter_seq)
    data_len2 = len(filenames)
    data_len_check = data_len1 == data_len2
    if not data_len_check:
        print('\nWARNING: You have a different number of images than entries in the log file!')
        print('Number of Filenames  : %i' %data_len2)
        print('Number of Log Entries: %i' %data_len1)
        print('\nPlease make sure you Log does not have unwanted entries and you have loaded in the right filename list.')
        print('\nProgram TERMINATED.\n')
        sys.exit(1)

    ## Now lets build a full test sequence of filters/exposure times
    ## and compare it to the actual Log info to see if anything went wrong
    fseq = []
    tseq = []
    for i in range(len(infer_seq)):
        num = infer_seq[i][1]
        for j in range(num):
            fseq.append(infer_seq[i][0])
            tseq.append(infer_seq[i][2])

    ## Now lets repeat the test sequence to build a full filter "log"
    ## the length of the actual dataset
    if filter_seq[0] == 'T':  # account for the first frame if it's a transition
        len_ratio = float((data_len1 - 1))/len(fseq)
        len_diff = int((len_ratio % 1) * len(fseq))
        fseq_full = fseq * int(np.floor(len_ratio)) + fseq[0:len_diff+1]
        tseq_full = tseq * int(np.floor(len_ratio)) + tseq[0:len_diff+1]
        fseq_full.insert(0,'T')
        tseq_full.insert(0,expose_seq[0])
    else:
        len_ratio = float(data_len1)/len(fseq)
        len_diff = int((len_ratio % 1) * len(fseq))
        fseq_full = fseq * int(np.floor(len_ratio)) + fseq[0:len_diff+1]
        tseq_full = tseq * int(np.floor(len_ratio)) + tseq[0:len_diff+1]


    # Now do te full check.  Unfortunately, only the first mismatch between
    # the test sequence and the real sequence can be reported.  If multiple
    # errors have occured, you will need to find them yourself :/
    ferr_count = 0
    terr_count = 0
    for i in range(data_len1):
        log_filt = filter_seq[i]
        log_texp = np.ceil(expose_seq[i])
        test_filt = fseq_full[i]
        test_texp = tseq_full[i]

        # Inform the user if a mismatch occurs, but do not
        # stop the program from running
        if (log_filt != test_filt) & (ferr_count == 0):
            print('\nFILTER MISMATCH on FRAME #%i' %(i+1,))
            print('Please check the log for errors.')
            ferr_count += 1

        if (log_texp != test_texp) & (terr_count == 0):
            print('\nEXPOSURE TIME MISMATCH on FRAME #%i' %(i+1,))
            print('Please check the log for errors.')
            terr_count += 1

    # Print a success message if everything matches
    if (ferr_count == 0) & (terr_count == 0):
        print('\nSUCCESS! No mismatches detected, your Filter Wheel Log is fine.')

else:
    print('\nQuality Check Skipped.')


###############################################################
##
##  First, let's add some basic info into the FITS
##  headers, namely the exposure time (in seconds), 
##  the filter being used, the object being observed,
##  the instrument being used, and the observer's initials.
##
##  Since this is multi-filter data, the exposure time 
##  and filter info can change from image to the next, so 
##  this information come from the Image_MetaData.log file.
##
###############################################################

## Inform the user what values will be changed and ask whether to proceed
print('\n\n#####################################################')
print('##          This section will add and edit         ##')
print('##         the following FITS header values:       ##')
print('## ----------------------------------------------- ##')
print('## EXPTIME  - The image exposure time              ##')
print('## FILTER   - The filter in use                    ##')
print('## OBJECT   - The object name e.g. SDSSJ1529+2928  ##')
print('## INSTRUME - The instrument used. e.g. ProEM      ##')
print('## OBSERVER - The initials of the observer         ##')
print('#####################################################')
print('')
check_edit_headers = raw_input('Would you like to proceed? (Y/[N]): ')
print('')

if (check_edit_headers == 'Y') or (check_edit_headers == 'y'):
    
    ## Define a function which runs the user through a
    ## prompting routine in order to change/keep a certain
    ## header keyword value.  An optional parameter is
    ## provided in case a 'best guess' at the header value
    ## is possible, such as for EXPTIME.
    def get_header_val(header_name,pass_value=None):
        
        ## Open the first FITS header
        hdu_temp = fits.open(path + filenames[0])
        
        ## Try reading the value of a header keyowrd
        try:
            ## If a pass_value was defined, use it to define header_value
            ## Else, try reading the header value from the FITS file
            if pass_value != None:
                header_value = pass_value
            else:
                ## This line throws a KeyError if the header_name
                ## keyword does not exist in the FITS header
                header_value = hdu_temp[0].header[header_name]
            
            ## If a current FILTER value exists, print it and
            ## ask the user if they want to change/keep it.
            print('%s = %s' %(header_name,header_value))
            change_value = raw_input('Change %s value? (Y/[N]): ' %header_name)
        
            if (change_value == 'Y') or (change_value == 'y'):
                new_value    = raw_input('Please provide new value for %s: ' %header_name)
                header_value = new_value
                print('')
            else:
                print('%s value was not changed.' %header_name)
                print('')
        
        ## KeyError will be thrown if you try to read a header
        ## value that does not exist.  In this case, simply ask
        ## for a value that will be added into the header later.
        except KeyError:
            header_value = raw_input('Please provide a value for %s: ' %header_name)

        ## Close the hdu
        hdu_temp.close()

        return header_value


    ## Use get_header_val to get values for each
    ## header keyword that needs to be added/edited
    object_name = get_header_val('OBJECT')
    instr_name  = get_header_val('INSTRUME')
    observ_name = get_header_val('OBSERVER')

    ## Let the user know what will be changed before proceeding
    print('\nThe following values will be added to the FITS headers:')
    print('EXPTIME   = Varies')
    print('FILTER    = Varies')
    print('OBJECT    = %s' %object_name)
    print('INSTRUME  = %s' %instr_name)
    print('OBSERVER  = %s' %observ_name)
    continue_edit_headers = raw_input('Continue? (Y/[N]): ')
    print('')

    ## Defining a function to open, edit, and save a
    ## new FITS file containing the new header info
    def edit_FITS(fname, texp0, filt):
        hdu    = fits.open(fname)                             
        prihdr = hdu[0].header                                
        prihdr.set('EXPTIME' ,texp0)                          
        prihdr.set('FILTER'  ,filt_name  ,comment='Filter Type',before='LONGSTRN')      
        prihdr.set('OBJECT'  ,object_name,comment='Object Name',before='LONGSTRN')    
        prihdr.set('INSTRUME',instr_name ,comment='Instrument Name',before='LONGSTRN')   
        prihdr.set('OBSERVER',observ_name,comment='Observer(s) Initials',before='LONGSTRN')  
        hdu2   = fits.PrimaryHDU(hdu[0].data,prihdr)          
        hdu2.writeto(fname, overwrite=True)                   
        hdu.close()
        return

    if (continue_edit_headers == 'Y') or (continue_edit_headers == 'y'):
    
        ## Loop through all FITS files in the working list
        ## and change their header values
        for i in range(num_files):
        
            ## Print Progress Bar
            count1  = i+1
            action1 = 'Editing header values..................'
            progress_bar(count1, num_files, action1)
        
            ## Now to actually open, edit, and save the FITS files
            filt_name = filter_seq[i]
            texp = np.ceil(expose_seq[i])
            edit_FITS(path + filenames[i], texp, filt_name)
        
        print('')
        print('')
        print('FITS header values were successfully edited.')

    else:
        print('FITS headers were not changed.')

else:
    print('FITS headers were not changed.')
    



################################################################
##
##  Now, let's perform the task which Keatons "mcdoheader2.py"
##  performs.  That is, we need to put the absolute timestamps
##  of start-exposure into the FITS header under the keywords of 
##  DATE-OBS and TIME-OBS.  A lot of the code here was taken 
##  directly from Keaton's with some slight modifications.
##
################################################################

## First load the timestamps CSV data file.
csv_name   = glob.glob('*_timestamps.csv')
path_csv   = path + csv_name[0]
time_data  = pd.read_csv(path_csv)

## Inform the user what values will be changed and ask whether to proceed
print('\n#####################################################')
print('##  This section will add and edit the following   ##')
print('##  FITS header values using a timestamps file:    ##')
print('## ----------------------------------------------- ##')
print('## DATE-OBS - UT Date at start of exposure         ##')
print('## TIME-OBS - UT Time at start of exposure         ##')
print('#####################################################')

print('\nTimestamps file:  %s' %csv_name[0])
check_add_times = raw_input('\nWould you like to proceed? (Y/[N]): ')
print('')

if (check_add_times == 'Y') or (check_add_times == 'y'):
    
    ## Defining a function which gets the exposure
    ## time from the FITS header
    def get_exptime(path_to_fits):
        hdu       = fits.open(path_to_fits)
        exptime   = float(hdu[0].header['EXPTIME'])
        hdu.close()
        return exptime    
    
    ## Defining a function to add timestamps to FITS files
    def addtimestamp(fitsname,timestamp):
        #fitsname is a string
        #timestamp is a datetime object
        hdu   = fits.open(fitsname.strip())       
        hdr   = hdu[0].header                     
        data  = hdu[0].data                       
        hdr.set('DATE-OBS',str(timestamp.date()),comment='UT Date at Start of Exposure') 
        hdr.set('TIME-OBS',str(timestamp.time()),comment='UT Time of Start of Exposure',after='DATE-OBS') 
        hdu2  = fits.PrimaryHDU(data,hdr)    
        hdu2.writeto(fitsname, overwrite=True, output_verify='ignore')
        hdu.close()
        return
        
    ## First, load the exposure times from the FITS
    ## frames and save them into a list.
    exp_times = []
    for i in range(num_files):
        ## Print progress bar
        count2  = i+1
        action2 = 'Loading Exp. Times from FITS headers...'
        progress_bar(count2, num_files, action2)
        
        texp = get_exptime(path + filenames[i])
        exp_times.append(texp)
        
    
    ## Perform a check to make sure the exposure times
    ## are in units of seconds, not milliseconds.  In
    ## practice, no exposure time has ever been as long
    ## as 500 seconds, but almost all exposures are longer
    ## than 500 milliseconds, so I'm using 500 as the 
    ## comparison value.
    exptime_zero = exp_times[0]
    print('\nFirst-Frame Exposure time: {} seconds.'.format(exptime_zero))
    if exptime_zero > 500:
        print('\nWARNING: Your exposure time value is VERY LARGE!')
        print('Make sure you have corrected the header exposure')
        print('times and converted them from milliseconds to seconds')
        
    ## Convert the timestamp.csv file loaded in the
    ## previous section from a Pandas data frame 
    ## object to a simple Numpy matrix array.
    raw_times = pd.DataFrame.as_matrix(time_data)
    
    ## Create empty lists to store data
    index   = []  # Frame tracking # for the images
    tstart  = []  # Time stamp for start of exposure
    tend    = []  # Time stamp for end of exposure
    dtstart = []  # t-delta b/t starts of current & previous frames
    dtend   = []  # t-delta b/t ends   of current & previous frames
      
    for line in raw_times:
        
        ## First split each line up into individually named values
        tindex, ttstart, ttend, tdtstart, tdtend = line
        ## Append the frame tracking # to the "index" list
        index.append(int(tindex))
        
        ## Next append the starting time stamp to "tstart".
        ## IF/ELSE statements check whether or not 
        ## micro-seconds were included in the CSV.  It's
        ## typical for microseconds to be included unless
        ## the metadata was not saved properly.
        if len(ttstart) != 26: # If no microseconds
            tstart.append(dt.strptime(ttstart,'%Y-%m-%d %H:%M:%S'))
        else:                  # If there are micro-seconds
            tstart.append(dt.strptime(ttstart,'%Y-%m-%d %H:%M:%S.%f'))
            
        ## Next append the ending time stamp to "tend"
        if len(ttend) != 26:   # If no microseconds
            tend.append(dt.strptime(ttend,'%Y-%m-%d %H:%M:%S'))
        else:                  # If there are microseconds
            tend.append(dt.strptime(ttend,'%Y-%m-%d %H:%M:%S.%f'))
            
        ## Lastly, append the start-to-start and end-to-end
        ## delta-t values between adjacent exposures.
        if isnan(tdtstart) == False: # If not the first frame
            dtstart.append(float(tdtstart)/1e9)
            dtend.append(float(tdtend)/1e9)
        else:                            # If the first frame
            dtstart.append(exptime_zero)
            dtend.append(exptime_zero)


    ## All times are defined relative to first frame
    tzero = tstart[0]
    ms    = tzero.microsecond # Number of microseconds in time stamp
    
    ## Any reason to worry that GPS triggering was not used?
    ## This IF statement checks whether the first time stamp 
    ## came more than 0.05 seconds before or after an 
    ## integer second.
    if (np.abs(ms - 1e6) > 5e4) & (np.abs(ms) > 5e4):
        print("WARNING: First exposure > 0.05 seconds away from integer second.")
        print("Check that you were using GPS triggers.")

    ## Round tzero to the nearest second
    ms = tzero.microsecond
    if ms > 5e5: #round up
        tzero += td(microseconds = 1e6 - ms)
    else:        #round down
        tzero += td(microseconds = -1 * ms)
        
    ## Create a list to hold the final timestamp values
    ## which will then be added into the FITS headers
    times = [tzero]
    #Add first timestamp to first fits file
    addtimestamp(path + filenames[0],times[0])

    #Determine accurate timestamps and place in fits headers.
    for i in range(1,num_files):
        
        ## Print progress bar
        count3  = i+1
        action3 = 'Adding timestamps to FITS headers......'
        progress_bar(count3, num_files, action3)
        
        ## Get the exposure time for the current frame
        exptime = exp_times[i]

        ## Check that the expected time has elapsed.
        ## Unfortunately, there's an indexing issue here.
        ## The exp-time for one frame has to be compared
        ## to the "dtstart" of the next frame.  This works
        ## fine until the last frame when there is no 
        ## longer a dtstart to compare to.  In that case.\,
        ## the "elif" statement below, I just compare to 
        ## the "dtend" of the same frame and hope for the best.
        if   (i < num_files-1  and round(exptime) == round(dtstart[i+1])):
            times.append(times[i-1] + td(seconds = round(dtstart[i])))
        elif (i == num_files-1 and round(exptime) == round(dtend[i])):
            times.append(times[i-1] + td(seconds = round(dtstart[i])))
        else:
            print('')
            print('')
            print "WARNING: timestamp anomaly on frame {}".format(index[i])
            ## Sometimes a bad timestamp comes down the line and 
            ## is corrected on the next exposure. Check to see if 
            ## things get back on track and the exposure time was 
            ## really the expected duration.
            ## WARNING! The checks below may or may not work for
            ## multi-filter data, yet to be confirmed.
            if i < len(index)-3:
                
                dt_check1  = dtstart[i]+dtstart[i+1]+dtstart[i+2]
                dt_check2  = dtstart[i-1]+dtstart[i]+dtstart[i+1]
                exp_check1 = exp_times[i]+exp_times[i+1]+exp_times[i+2]
                exp_check2 = exp_times[i-1]+exp_times[i]+exp_times[i+1]
                
                if round(dt_check1) == round(exp_check1):
                    print("It appears to get back on track.")
                    times.append(times[i-1] + td(seconds = round(exptime)))
                elif round(dt_check2) == round(exp_check2):
                    print("Making up for the last frame.")
                    times.append(times[i-1] + td(seconds = round(exptime)))
                else:
                    print("Looks like triggers were missed.")
                    times.append(times[i-1] + td(seconds = round(dtstart[i])))
            else:
                print("Last couple of timestamps from this run are suspect.")
                times.append(times[i-1] + td(seconds = round(exptime)))
            
        ## Add timestamp to fits file:
        addtimestamp(path + filenames[i],times[-1])
    
    print('')
    print('\nUT timestamps successfully added to FITS headers')
    print('under the keywords DATE-OBS and TIME-OBS.\n')
    
else:
    print('Timestamps were not added to the FITS headers\n')


###############################################################
##
##    Lastly, let's move the FITS files into new folders
##    based on their FILTER position.
##
###############################################################
print('#####################################################')
print('##      This section will move FITS files into     ##')
print('##   new directories created for each filter type. ##')
print('##                                                 ##')
print('##      To run this section, you should have       ##')
print('##    already added FILTER and EXPTIME info in     ##')
print('##    to the headers. If not, moving will fail.    ##')
print('#####################################################')
check_rename = raw_input('\nContinue with file moving? (Y/[N]): ')

if (check_rename == 'Y') or (check_rename == 'y'):

    # Provide user with options about which direction to move the folders
    print('\n OPTION 1: Move files into folders separated by filter type.')
    print(' OPTION 2: Move files from separated folders back to original folder.')
    check_separate = raw_input("\n Please select which operation you'd like to perform (1 or 2): ")

    # make sure the input is good
    if (check_separate != '1') & (check_separate != '2'):
        while (check_separate != '1') & (check_separate != '2'):
            check_separate = raw_input('Invalid option, please choose option 1 or 2, or enter "q" to quit: ')
            if check_separate == 'q':
                print('Program TERMINATED')
                sys.exit(1)

    ## Defining a function which gets the exposure
    ## time and filter info from the FITS file header
    def get_info(path_to_fits):
        hdu          = fits.getheader(path_to_fits)
        texp_frame   = float(hdu['EXPTIME'])
        filt_frame   = hdu['FILTER']
        return texp_frame,filt_frame

    ## Defining a function to move file from one
    ## directroy to another
    def rename(old_path,new_path):
        try:
            os.rename(old_path,new_path)
        except OSError as e:
            if e.errno != errno.ENOENT:
                raise
            else:
                _,_,traceback = sys.exc_info()
                print('Line #%i, Directory or Filename does not exist.' %traceback.tb_lineno)
        return

    ## Make new filter directories if they don't already exist
    directory_dict = {x : x + '_frames' for x in filt_look}
    for key,name in directory_dict.iteritems():
        try:
            os.makedirs(name)
        except OSError as e:
            if e.errno != errno.EEXIST:
                raise
            else:
                print('Directory %s already exists.' %name)


    count4 = 0
    for f in filenames:
        ## Printing the progress bar
        count4 += 1
        action4 = 'Separating files by filter type........'
        progress_bar(count4, num_files, action4)

        # If separating files into folder by filter type
        if check_separate == '1':
            file_texp,file_filt = get_info(path + f)
            dname = directory_dict[file_filt]
            old_path = path + f
            new_path = path + dname + '/' + f
            rename(old_path,new_path)
        
        # If bringing all files back to a common folder
        elif check_separate == '2':
            # Find the current path for a given filename
            found = 0
            for pf,df,ff in os.walk(path):
                if any([x==f for x in ff]):
                    old_path = pf + f
                    found += 1
                if found > 0:
                    break
                else:
                    continue

            # Set the new path and check to make sure it's different
            new_path = path + f
            if new_path == old_path:
                print('\nFile is already in the common folder, moving is not necessary.')
                continue
            else:
                rename(old_path,new_path)


    print('\nFITS files were successfully moved.\n')


else:
    print('FITS files were not moved.')

# Print final message
print('')
print('                  Program COMPLETE!\n\n')



    











